{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rte1:\n",
    "\n",
    "### Model : 9a275f9320714938a25097c942b35477"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113550333/113550333 [00:11<00:00, 9761023.58it/s] \n",
      "100%|██████████| 113550333/113550333 [00:12<00:00, 8940892.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len gtruth_class 113550333\n",
      "gtruth unique classes [  2   3   4   5   6  14  50  51  56  70  71  72  79 106 107 111 150 151\n",
      " 161 196 197 211 212 213]\n",
      "\n",
      "len rte1_gtruth_class 113550333\n",
      "unique gtruth classes merged classe [  1   2   5   6  14  56  59  70  71  72  79 196 211]\n",
      "\n",
      "len pred_class113550333\n",
      " unique classe predictions[  1   2   5   6  59  72 196]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len ground_truth 113550333\n",
      "len pred 113550333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113550333/113550333 [06:42<00:00, 282155.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "13\n",
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte1 correctement labelise/metrics\\conf_matrix_000006.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte1 correctement labelise/metrics\\000006_metric_frame.xlsx\n",
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte1 correctement labelise/metrics\\000006_weighted_m.xlsx\n"
     ]
    }
   ],
   "source": [
    "#from onlymodel import show_metric\n",
    "#from metricsyso import *\n",
    "\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from metricsyso import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "def show_metric(truthpath, predpath, savepath):\n",
    "    # Créez le répertoire de sauvegarde s'il n'existe pas\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "    pred_filename = os.path.splitext(os.path.basename(predpath))[0]\n",
    "    \n",
    "    conv_dict1 = {\"1\": 0,\"2\": 1,\"3\": 0,\"4\": 2,\"5\": 2, \"6\": 3,\"7\": 8,\"12\": 0,\"13\": 0,\"15\": 0,\"50\": 4,\"51\": 4,\n",
    "            \"52\": 4, \"53\": 4,\"54\": 4, \"55\": 4, \"64\": 4,\"72\": 7, \"101\": 5,\"102\": 5,\"103\": 5, \"104\": 5,\n",
    "        \"105\": 5,\"106\": 5,\"107\": 5, \"108\": 5,\"109\": 5,\"110\": 5,\"111\": 5,\"120\": 5,\"121\": 5,\"150\": 6, \"151\": 6,\n",
    "    \"152\": 6,\"53\": 6, \"154\": 6,\"155\": 6, \"160\": 6, \"161\": 6, \"185\": 6, \"196\": 5,\n",
    "    \"197\": 5,\"200\": 6,\"201\": 6, \"202\": 6,\"211\": 6,\"212\": 6,\"213\": 6, \"221\": 6, \"222\": 6,\"223\": 6\n",
    "    }\n",
    "    model1 = {\"0\":1, \"1\":2, \"2\":5, \"3\":6, \"4\":59, \"5\":196, \"6\": 211, \"7\":72}\n",
    "\n",
    "#\n",
    "\n",
    "    direct_conv1={k:j for k, v in conv_dict1.items() for  i, j in model1.items()  if int(i) == v }\n",
    "\n",
    "\n",
    "    # Exemple d'utilisation\n",
    "    rte1_pred=read_file_class(predpath)\n",
    "    rte1_truth=read_file_class(truthpath)\n",
    "    pred_class = num_points(rte1_pred)\n",
    "    gtruth_class = num_points(rte1_truth)\n",
    "\n",
    "\n",
    "    gtruth_cleanead = [direct_conv1.get(str(k)) if direct_conv1.get(str(k)) is not None else k for k in gtruth_class]\n",
    "\n",
    "    rte1_ground_truth =np.array(gtruth_cleanead)\n",
    "    rte1_predictions = np.array(pred_class)\n",
    "    \n",
    "    print(\"len gtruth_class\",len(gtruth_class))\n",
    "    print(\"gtruth unique classes\",np.unique(gtruth_class))    \n",
    "    print(\"\") \n",
    "    print(\"len rte1_gtruth_class\", len(rte1_ground_truth))\n",
    "    print(\"unique gtruth classes merged classe\", np.unique(rte1_ground_truth))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(f\"len pred_class{len(rte1_predictions)}\")\n",
    "    print(f\" unique classe predictions{np.unique(rte1_predictions)}\")\n",
    "    print(\"\")\n",
    "\n",
    "    unique_classes =  np.unique(np.concatenate((rte1_ground_truth, rte1_predictions)))\n",
    "    clas_name = [str(name) for name in tqdm(unique_classes)]\n",
    "\n",
    "    default_dict = {\"1\":\"default\",\"2\":\"ground\",\"5\": \"vegetation\", \n",
    "                \"6\":\"building\",\"7\": \"wall\", \n",
    "                \"196\": \"structure\",\"211\":\"cable\"\n",
    "                }\n",
    "\n",
    "    conf_matrix = compute_confusion_matrix(rte1_ground_truth, rte1_predictions)\n",
    "    \n",
    "    print(conf_matrix.shape[0])\n",
    "    print(len(clas_name))\n",
    "    if conf_matrix.shape[0] != len(clas_name) or conf_matrix.shape[1] != len(clas_name):\n",
    "        raise ValueError(\"Mismatch between confusion matrix dimensions and class names\")\n",
    "          \n",
    "    #conf_matrix = confusion_matrix(rte1_ground_truth, rte1_predictions)\n",
    "\n",
    "    # Sauvegarder la matrice de confusion dans un fichier Excel\n",
    "    with pd.ExcelWriter(os.path.join(savepath, f\"conf_matrix_{pred_filename}.xlsx\")) as writer:\n",
    "\n",
    "        #df = pd.DataFrame(conf_matrix, index=clas_name, columns=clas_name)\n",
    "        conf_matrix.rename(columns = default_dict, index = default_dict, inplace = True)\n",
    "        conf_matrix.to_excel(writer, index=True)\n",
    "        print(f\"Fichier sauvegardé avec succès: {os.path.join(savepath, f'conf_matrix_{pred_filename}.xlsx')}\")\n",
    "\n",
    "    # Afficher et sauvegarder la matrice de confusion\n",
    "        \n",
    "    #ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=clas_name)\n",
    "    \"\"\"dis=ConfusionMatrixDisplay.from_predictions(rte1_ground_truth, rte1_predictions, labels = clas_name )\n",
    "    mask = np.eye(len(conf_matrix))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(30, 10))\n",
    "    #ConfusionMatrixDisplay(conf_matrix, display_labels=clas_name).plot(ax=ax)\n",
    "    dis.plot(ax=ax)\n",
    "    ax.imshow(mask, cmap='Blues', interpolation='nearest', alpha=0.5)\n",
    "\n",
    "    plt.savefig(os.path.join(savepath, f\"conf_matrix_{pred_filename}.png\"))\n",
    "    plt.show()\"\"\"\n",
    "    \n",
    "    \n",
    "    #========================== metrics=============================================#\n",
    "    \n",
    "    metrics=Metrics(rte1_ground_truth,rte1_predictions)\n",
    "    ## calling a methods for computing metrics\n",
    "    m=metrics.compute_metrics()\n",
    "\n",
    "    ## for displaying as frame\n",
    "\n",
    "    fr = metrics.metrics_frame(m)\n",
    "    wg = metrics.weighted_metrics()\n",
    "\n",
    "\n",
    "    # Sauvegarder la matrice de confusion dans un fichier Excel\n",
    "    with pd.ExcelWriter(os.path.join(savepath, f\"{pred_filename}_metric_frame.xlsx\")) as writer:\n",
    "        \n",
    "        fr.rename(columns =default_dict,index = default_dict, inplace = True)\n",
    "        fr.to_excel(writer, index=True)\n",
    "        print(f\"Fichier sauvegardé avec succès: {os.path.join(savepath, f'{pred_filename}_metric_frame.xlsx')}\")\n",
    "\n",
    "\n",
    "    # Sauvegarder la matrice de confusion dans un fichier Excel\n",
    "    with pd.ExcelWriter(os.path.join(savepath, f\"{pred_filename}_weighted_m.xlsx\")) as writer:\n",
    "        wg.rename(columns =default_dict, index = default_dict, inplace = True)\n",
    "        wg.to_excel(writer, index=True)\n",
    "        print(f\"Fichier sauvegardé avec succès: {os.path.join(savepath, f'{pred_filename}_weighted_m.xlsx')}\")\n",
    "        \n",
    "truthpath = r\"E:/S_Données_pour apprentissage/Données pour prédiction sans bruit/000006.laz\"\n",
    "## Use the predited files path \n",
    "predpath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte1 correctement labelise/db3ea63f541a4d9fbe68bd96f98a86ae/preds/000006.laz\"\n",
    "savepath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte1 correctement labelise/metrics\"\n",
    "show_metric(truthpath,predpath,savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from tkinter import font, filedialog, messagebox\n",
    "import json\n",
    "from metricsyso import *\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MyApp():\n",
    "    def __init__(self,windows):\n",
    "        self.windows = windows\n",
    "        windows.title(\"My App\")\n",
    "        self.conf_df = None\n",
    "        self.df_m =None \n",
    "        self.df_w =None\n",
    "        self.default_dict = default_dict = {\"1\":\"default\",\"2\":\"ground\",\"5\": \"vegetation\", \n",
    "                \"6\":\"building\",\"7\": \"wall\", \n",
    "                \"196\": \"structure\",\"211\":\"cable\"\n",
    "                }\n",
    "        #self.button = Button(windows,text=\"Display confsusion matrix\", command =self.compute_metrics).place(x=60, y=45,height = 50, width = 180)\n",
    "        \n",
    "        # Create buttons to compute metrics\n",
    "        self.compute_button = tk.Button(windows, text=\"Compute Metrics\",command=lambda: self.compute_metrics)\n",
    "        self.compute_button.place(x=60, y=45,height = 50, width = 180)\n",
    "       \n",
    "        \n",
    "        self.button1 = Button(windows,text=\"Display confsusion matrix\", command =self.display_confmatrix).place(x=60, y=200,height = 50, width = 180)\n",
    "      \n",
    "        self.button2 = Button(windows,text=\"Display metrics\", command =self.display_df_metrics).place(x=60, y=260,height = 50, width = 180)\n",
    "       \n",
    "        self.buton3 = Button(windows,text=\"Display weighted metrics\", command =self.display_weightetd_metrics).place(x=60, y=340,height = 50, width =180)\n",
    "       \n",
    "        self.gtruth_file_entry = Entry(windows, width=50)\n",
    "        self.gtruth_file_entry.pack()\n",
    "        self.gtruth_file_btn = tk.Button(windows, text=\"Load Ground Truth File\", command=lambda: self.gtruth_file_entry.insert(tk.END, self.browse_file(\"Select Ground Truth File\")))\n",
    "        self.gtruth_file_btn.pack()\n",
    "        \n",
    "        self.pred_file_entry = Entry(windows, width=50)\n",
    "        self.pred_file_entry.pack()\n",
    "        self.pred_file_btn = tk.Button(windows, text=\"Load Prediction File\", command=lambda: self.pred_file_entry.insert(tk.END, self.browse_file(\"Select Prediction File\")))\n",
    "        self.pred_file_btn.pack()\n",
    "        \n",
    "        self.json_file_entry = Entry(windows, width=50)\n",
    "        self.json_file_entry.pack()\n",
    "        self.json_file_btn = tk.Button(windows, text=\"Load JSON File\", command=lambda: self.json_file_entry.insert(tk.END, self.browse_file(\"Select JSON File\")))\n",
    "        self.json_file_btn.pack()\n",
    "        \n",
    "        # place the pbbar\n",
    "        self.pb = ttk.Progressbar(windows, orient='horizontal',    mode='indeterminate',    length=280)\n",
    "        self.pb.place(x=60, y=100,height = 20, width = 180)\n",
    "        \n",
    "        self.status_label = tk.Label(windows, text=\"\", padx=20, pady=10)\n",
    "        self.status_label.pack()\n",
    "        \n",
    "        self.save_button = tk.Button(windows, text=\"Save to File\", command=self.save_to_file)\n",
    "        self.save_button.pack(pady=10)\n",
    "        \n",
    "        self.text_widget = tk.Text(windows, wrap=tk.WORD)\n",
    "        self.text_widget.pack(padx=20, pady=20, fill=\"both\", expand=True)\n",
    "\n",
    "    def browse_file(self,title):\n",
    "        filepath = filedialog.askopenfilename(title=title, filetypes=((\"Laz or Las files\", \"*.laz *.las\"), (\"All files\", \"*.*\")))\n",
    "        return filepath\n",
    "\n",
    "\n",
    "    def tree_display(self,df):\n",
    "            df_list=list(df.columns.values)\n",
    "            df_rset=df.to_numpy().tolist()\n",
    "            df_tree=ttk.Treeview(self.windows,columns=df_list)\n",
    "            df_tree.pack()                                      \n",
    "            for i in df_list:\n",
    "                df_tree.column(i,width=100,anchor='c')\n",
    "                df_tree.heading(i,text=i)\n",
    "            for dt in df_rset:\n",
    "                v=[r for r in dt]\n",
    "                df_tree.insert('','end', values=v)\n",
    "            df_tree.tag_configure('ttk', background='yellow')\n",
    "\n",
    "    def compute_metrics(self):\n",
    "        \n",
    "        gtruth_file =self.gtruth_file_entry.get()\n",
    "        pred_file = self.pred_file_entry.get()\n",
    "        json_file = self.json_file_entry.get()\n",
    "        \n",
    "        \n",
    "        # Reset pb bar\n",
    "        self.pb['value'] = 0\n",
    "        self.windows.update_idletasks()\n",
    "        \n",
    "        # step 1: Load Json file\n",
    "        op = JsonFile(json_file)\n",
    "        conv_dict = op.convdict()\n",
    "        conv_class = op.convclass()\n",
    "        truth_class = op.conv_to_Truclass(conv_dict, conv_class)\n",
    "        self.pb['value'] = 20\n",
    "        self.windows.update_idletasks() \n",
    "\n",
    "        # Step 1 : read gtruth file and  pred file\n",
    "        gtruth = read_file_class(gtruth_file)\n",
    "        prediction = read_file_class(pred_file)\n",
    "        count_pred = num_points(prediction)\n",
    "        count_gtruth = num_points(gtruth)\n",
    "        self.pb['value'] = 40\n",
    "        self.windows.update_idletasks()\n",
    "        \n",
    "        # step 3 : convert gtruth classes\n",
    "        convertor = truth_class\n",
    "        gtruth_conv = [convertor.get(str(k)) if convertor.get(str(k)) is not None else k for k in count_gtruth]\n",
    "        self.pb['value'] = 60\n",
    "        self.windows.update_idletasks()\n",
    "\n",
    "        # step 4 : conpute confusion matrix\n",
    "        input_pred = np.array(count_pred)\n",
    "        input_gtruth = np.array(gtruth_conv)\n",
    "        unique_classes =  np.unique(np.concatenate((input_gtruth, input_pred )))\n",
    "        self.clas_name = [str(name) for name in tqdm(unique_classes)]\n",
    "        self.conf_df= compute_confusion_matrix(input_gtruth, input_pred)\n",
    "        self.conf_df.rename(columns = self.default_dict, index = self.default_dict, inplace = True)\n",
    "        self.pb['value'] = 80\n",
    "        self.windows.update_idletasks()\n",
    "        \n",
    "        # Step 5 compute metrics\n",
    "        m = Metrics(input_gtruth, input_pred)\n",
    "        metrics_fr = m.compute_metrics()\n",
    "        self.df_m =m.metrics_frame(metrics_fr)\n",
    "        self.df_w = m.weighted_metrics()\n",
    "        self.pb['value'] = 100\n",
    "        self.windows.update_idletasks()\n",
    "\n",
    "    \n",
    "\n",
    "    # displayinf data frame witrh a treeView\n",
    "    \n",
    "    def display_confmatrix(self):\n",
    "        self.tree_display(self.conf_df)\n",
    "\n",
    "    def display_df_metrics(self):\n",
    "        self.tree_display(self.df_m)\n",
    "\n",
    "    def display_weightetd_metrics(self):\n",
    "        self.tree_display(self.df_w)\n",
    "        \n",
    "        \n",
    "    \"\"\"def self.save_to_file (self):\n",
    "        path = asksaveasfile()\n",
    "        with pd.ExcelWriter(path, engine =\"openpyxl\", mode =\"a\") as writer:\n",
    "            self.conf_df.to_excel(writer, index=True)\n",
    "            print(f\"Fichier sauvegardé avec succès: {os.path.join(savepath, f'conf_matrix_{pred_filename}.xlsx')}\")\"\"\"\n",
    "            \n",
    "\n",
    "    def save_to_file(self):\n",
    "        \n",
    "        file_path = filedialog.asksaveasfilename(defaultextension=\".xlsx\", filetypes=[(\"Text files\", \"*.txt\"), (\"All files\", \"*.*\")])\n",
    "        if file_path:\n",
    "            \n",
    "            try:                \n",
    "                with open (file_path,'w') as file:\n",
    "                    \n",
    "                    text_content = self.text_widget.get(\"1.0\", \"end-1c\")\n",
    "                file.write(text_content)\n",
    "                     \n",
    "            except Exception as e:\n",
    "                self.status_label.config(text=f\"Error saving file: {str(e)}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "windows =Tk()\n",
    "my_gui = MyApp(windows)\n",
    "\n",
    "windows.geometry('900x600')\n",
    "windows.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rte2:\n",
    "\n",
    "### Model : d167dd0644634a8eaee6241ed7c375ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SaveMetrics import show_metrics\n",
    "from metricsyso import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113550333/113550333 [00:11<00:00, 10049444.83it/s]\n",
      "100%|██████████| 113550333/113550333 [00:11<00:00, 10048648.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len gtruth_class 113550333\n",
      "gtruth unique classes [  2   3   4   5   6  14  50  51  56  70  71  72  79 106 107 111 150 151\n",
      " 161 196 197 211 212 213]\n",
      "\n",
      "len rte1_gtruth_class 113550333\n",
      "unique gtruth classes merged classe [  1   2   5   6  14  56  59  70  71  72  79 196 211]\n",
      "\n",
      "len pred_class113550333\n",
      " unique classe predictions[  1   2   5   6 196 211]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len ground_truth 113550333\n",
      "len pred 113550333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113550333/113550333 [06:39<00:00, 283953.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "13\n",
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_sans_intensity/metrics\\conf_matrix_000006.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_sans_intensity/metrics\\000006_metric_frame.xlsx\n",
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_sans_intensity/metrics\\000006_weighted_m.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "truthpath = r\"E:/S_Données_pour apprentissage/Données pour prédiction sans bruit/000006.laz\"\n",
    "## Use the predited files path \n",
    "predpath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_sans_intensity/d167dd0644634a8eaee6241ed7c375ce/preds/000006.laz\"\n",
    "savepath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_sans_intensity/metrics\"\n",
    "show_metric(truthpath,predpath,savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model : b478f486891d47aca0ad2b5f116d48c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113550333/113550333 [00:11<00:00, 9858535.87it/s] \n",
      "100%|██████████| 113550333/113550333 [00:11<00:00, 9946526.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len gtruth_class 113550333\n",
      "gtruth unique classes [  2   3   4   5   6  14  50  51  56  70  71  72  79 106 107 111 150 151\n",
      " 161 196 197 211 212 213]\n",
      "\n",
      "len rte1_gtruth_class 113550333\n",
      "unique gtruth classes merged classe [  1   2   5   6  14  56  59  70  71  72  79 196 211]\n",
      "\n",
      "len pred_class113550333\n",
      " unique classe predictions[  1   2   5   6 196 211]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len ground_truth 113550333\n",
      "len pred 113550333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113550333/113550333 [06:43<00:00, 281230.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "13\n",
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008_15/metrics\\conf_matrix_000006.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008_15/metrics\\000006_metric_frame.xlsx\n",
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008_15/metrics\\000006_weighted_m.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "truthpath = r\"E:/S_Données_pour apprentissage/Données pour prédiction sans bruit/000006.laz\"\n",
    "## Use the predited files path \n",
    "predpath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008_15/b478f486891d47aca0ad2b5f116d48c2/preds/000006.laz\"\n",
    "savepath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008_15/metrics\"\n",
    "show_metric(truthpath,predpath,savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model : 3285002e42f64f02af799c9ffdc4ffb6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113550333/113550333 [00:11<00:00, 9931088.10it/s] \n",
      "100%|██████████| 113550333/113550333 [00:11<00:00, 9983511.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len gtruth_class 113550333\n",
      "gtruth unique classes [  2   3   4   5   6  14  50  51  56  70  71  72  79 106 107 111 150 151\n",
      " 161 196 197 211 212 213]\n",
      "\n",
      "len rte1_gtruth_class 113550333\n",
      "unique gtruth classes merged classe [  1   2   5   6  14  56  59  70  71  72  79 196 211]\n",
      "\n",
      "len pred_class113550333\n",
      " unique classe predictions[  1   2   5   6 196 211]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len ground_truth 113550333\n",
      "len pred 113550333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113550333/113550333 [06:42<00:00, 281885.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "13\n",
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008-16/metrics\\conf_matrix_000006.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008-16/metrics\\000006_metric_frame.xlsx\n",
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008-16/metrics\\000006_weighted_m.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "truthpath = r\"E:/S_Données_pour apprentissage/Données pour prédiction sans bruit/000006.laz\"\n",
    "## Use the predited files path \n",
    "predpath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008-16/3285002e42f64f02af799c9ffdc4ffb6/preds/000006.laz\"\n",
    "savepath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008-16/metrics\"\n",
    "show_metric(truthpath,predpath,savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model : 99385bdd1b4245d6813754f478bd5f2c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113550333/113550333 [00:11<00:00, 9984146.94it/s] \n",
      "100%|██████████| 113550333/113550333 [00:11<00:00, 10016476.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len gtruth_class 113550333\n",
      "gtruth unique classes [  2   3   4   5   6  14  50  51  56  70  71  72  79 106 107 111 150 151\n",
      " 161 196 197 211 212 213]\n",
      "\n",
      "len rte2_gtruth_class 113550333\n",
      "unique gtruth classes merged classe [  1   2   5   6  14  56  70  71  79 196 211]\n",
      "\n",
      "len pred_class113550333\n",
      " unique classe predictions[  1   2   5   6 196 211]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len ground_truth 113550333\n",
      "len pred 113550333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113550333/113550333 [06:37<00:00, 285477.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte2 correctement labelise/metrics\\conf_matrix_000006.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte2 correctement labelise/metrics\\000006_metric_frame.xlsx\n",
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte2 correctement labelise/metrics\\000006_weighted_m.xlsx\n"
     ]
    }
   ],
   "source": [
    "from SaveMetrics import show_metrics\n",
    "from metricsyso import *\n",
    "\n",
    "truthpath = r\"E:/S_Données_pour apprentissage/Données pour prédiction sans bruit/000006.laz\"\n",
    "## Use the predited files path \n",
    "predpath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte2 correctement labelise/99385bdd1b4245d6813754f478bd5f2c/preds/000006.laz\"\n",
    "savepath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte2 correctement labelise/metrics\"\n",
    "show_metrics(truthpath,predpath,savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dalle 00004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model : 3285002e42f64f02af799c9ffdc4ffb6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SaveMetrics import show_metrics\n",
    "from metricsyso import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58898000/58898000 [00:06<00:00, 9499354.06it/s] \n",
      "100%|██████████| 58898000/58898000 [00:06<00:00, 9372412.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len gtruth_class 58898000\n",
      "gtruth unique classes [  2   3   5   6  14  56  60  72 111 161 196 197 200 211 212 213]\n",
      "\n",
      "len rte2_gtruth_class 58898000\n",
      "unique gtruth classes merged classe [  1   2   5   6  14  56  60 196 211]\n",
      "\n",
      "len pred_class58898000\n",
      " unique classe predictions[  1   2   5   6 196 211]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len ground_truth 58898000\n",
      "len pred 58898000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58898000/58898000 [03:27<00:00, 284206.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008-15v2/metrics04\\conf_matrix_000004.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008-15v2/metrics04\\000004_metric_frame.xlsx\n",
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008-15v2/metrics04\\000004_weighted_m.xlsx\n"
     ]
    }
   ],
   "source": [
    "truthpath = r\"E:/S_Données_pour apprentissage/Données pour prédiction sans bruit/000004.laz\"\n",
    "## Use the predited files path \n",
    "predpath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008-15v2/3285002e42f64f02af799c9ffdc4ffb6/preds/000004.laz\"\n",
    "savepath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008-15v2/metrics04\"\n",
    "show_metrics(truthpath,predpath,savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model : d167dd0644634a8eaee6241ed7c375ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58898000/58898000 [00:06<00:00, 9789101.73it/s] \n",
      "100%|██████████| 58898000/58898000 [00:06<00:00, 9815205.39it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len gtruth_class 58898000\n",
      "gtruth unique classes [  2   3   5   6  14  56  60  72 111 161 196 197 200 211 212 213]\n",
      "\n",
      "len rte2_gtruth_class 58898000\n",
      "unique gtruth classes merged classe [  1   2   5   6  14  56  60 196 211]\n",
      "\n",
      "len pred_class58898000\n",
      " unique classe predictions[  1   2   5   6 196 211]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len ground_truth 58898000\n",
      "len pred 58898000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58898000/58898000 [03:30<00:00, 280310.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_sans_intensity/metrics04\\conf_matrix_000004.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_sans_intensity/metrics04\\000004_metric_frame.xlsx\n",
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_sans_intensity/metrics04\\000004_weighted_m.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "truthpath = r\"E:/S_Données_pour apprentissage/Données pour prédiction sans bruit/000004.laz\"\n",
    "## Use the predited files path \n",
    "predpath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_sans_intensity/d167dd0644634a8eaee6241ed7c375ce/preds/000004.laz\"\n",
    "savepath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_sans_intensity/metrics04\"\n",
    "show_metrics(truthpath,predpath,savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dalle 000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model : 3285002e42f64f02af799c9ffdc4ffb6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94723017/94723017 [00:09<00:00, 9877464.83it/s] \n",
      "100%|██████████| 94723017/94723017 [00:09<00:00, 9518763.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len gtruth_class 94723017\n",
      "gtruth unique classes [  2   3   4   5   6  14  56  60  72  79 103 104 105 107 109 151 153 154\n",
      " 155 196 197 200 211 212 213]\n",
      "\n",
      "len rte2_gtruth_class 94723017\n",
      "unique gtruth classes merged classe [  1   2   5   6  14  56  60  79 196 211]\n",
      "\n",
      "len pred_class94723017\n",
      " unique classe predictions[  1   2   5   6 196 211]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len ground_truth 94723017\n",
      "len pred 94723017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94723017/94723017 [05:37<00:00, 280591.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008-15v2/metrics01\\conf_matrix_000001.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008-15v2/metrics01\\000001_metric_frame.xlsx\n",
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008-15v2/metrics01\\000001_weighted_m.xlsx\n"
     ]
    }
   ],
   "source": [
    "truthpath = r\"E:/S_Données_pour apprentissage/Données pour prédiction sans bruit/000001.laz\"\n",
    "## Use the predited files path \n",
    "predpath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008-15v2/3285002e42f64f02af799c9ffdc4ffb6/preds/000001.laz\"\n",
    "savepath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_008-15v2/metrics01\"\n",
    "show_metrics(truthpath,predpath,savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model : d167dd0644634a8eaee6241ed7c375ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94723017/94723017 [00:09<00:00, 9784815.00it/s] \n",
      "100%|██████████| 94723017/94723017 [00:09<00:00, 9882645.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len gtruth_class 94723017\n",
      "gtruth unique classes [  2   3   4   5   6  14  56  60  72  79 103 104 105 107 109 151 153 154\n",
      " 155 196 197 200 211 212 213]\n",
      "\n",
      "len rte2_gtruth_class 94723017\n",
      "unique gtruth classes merged classe [  1   2   5   6  14  56  60  79 196 211]\n",
      "\n",
      "len pred_class94723017\n",
      " unique classe predictions[  1   2   5   6 196 211]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10003.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len ground_truth 94723017\n",
      "len pred 94723017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94723017/94723017 [05:41<00:00, 277731.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_sans_intensity/metrics01\\conf_matrix_000001.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ysouley\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_sans_intensity/metrics01\\000001_metric_frame.xlsx\n",
      "Fichier sauvegardé avec succès: E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_sans_intensity/metrics01\\000001_weighted_m.xlsx\n"
     ]
    }
   ],
   "source": [
    "truthpath = r\"E:/S_Données_pour apprentissage/Données pour prédiction sans bruit/000001.laz\"\n",
    "## Use the predited files path \n",
    "predpath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_sans_intensity/d167dd0644634a8eaee6241ed7c375ce/preds/000001.laz\"\n",
    "savepath = r\"E:/S_Données_pour apprentissage/data_output inference/Donnees  labelises en sortie d'inference/rte3_sans_intensity/metrics01\"\n",
    "show_metrics(truthpath,predpath,savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
